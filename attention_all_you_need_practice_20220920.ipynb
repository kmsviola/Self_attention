{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from torchtext==0.6.0) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from torchtext==0.6.0) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from torchtext==0.6.0) (4.64.0)\n",
      "Requirement already satisfied: six in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: torch in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from torchtext==0.6.0) (1.12.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2022.6.15)\n",
      "Requirement already satisfied: typing-extensions in /Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/lib/python3.7/site-packages (from torch->torchtext==0.6.0) (4.3.0)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Attention_is_All_You_Need_Tutorial_(German_English).ipynb\n",
    "\n",
    "!pip install torchtext==0.6.0\n",
    "# BLEU Score 계산을 위한 라이브러리 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/bin/python: No module named spacy\n",
      "/Users/kmsviola_pro16/opt/anaconda3/envs/nlp_37/bin/python: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "# spaCy 라이브러리: 문장의 토큰화(tokenization), 태깅(tagging) 등의 전처리 기능을 위한 라이브러리\n",
    "# 영어(Engilsh)와 독일어(Deutsch) 전처리 모듈 설치\n",
    "# 가상환경 terminal에서 설치 \n",
    "\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm') # English tokenization\n",
    "spacy_de = spacy.load('de_core_news_sm') # German tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: I\n",
      "index 1: am\n",
      "index 2: a\n",
      "index 3: graduate\n",
      "index 4: student\n",
      "index 5: .\n"
     ]
    }
   ],
   "source": [
    "#간단한 토큰화 기능 써보기\n",
    "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
    "\n",
    "for i, token in enumerate(tokenized):\n",
    "    print(f\"index {i}: {token.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장에 대해 토큰화를 수행하여 리스트 형태로 반환하기 \n",
    "# 독일어 문장을 토큰화 하는 함수 (순서를 뒤집지 않음) \n",
    "def tokenize_de(text):\n",
    "    return [token.text for token in spacy_de.tokenizer(text)]\n",
    "\n",
    "# 영어 문장을 토큰화 하는 함수\n",
    "def tokenize_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필드 라이브러리를 이용해 데이터셋에 대해 구체적인 전처리 내용을 명시합니다. \n",
    "# 어떠한 데이터셋에 대해 전처리를 세팅\n",
    "# Seq2Seq 모델과는 다르게 batch_first 속성 값을 True로 설정합니다. \n",
    "# 번역 목표 \n",
    " # 소스(SRC) : 독일어\n",
    " # 목표(TRG) : 영어 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "SRC = Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\n",
    "\n",
    "# 시작은 <sos> 끝은 <eos>를 붙이고 lower = True는 소문자로 변환, transformer에 입력을 넣을 때는 텐서의 차원에서 시퀀스보다는 배치가 먼저 오도록 만드는 경우가 많다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대표적인 영어-독어 번역 데이터셋인 Multi30k를 불러오기 독일어를 영어로 바꾸는 태스크..\n",
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset_size: 29000\n",
      "valid_dataset_size: 1014\n",
      "test_dataset_size: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"training_dataset_size: {len(train_dataset.examples)}\")\n",
    "print(f\"valid_dataset_size: {len(valid_dataset.examples)}\")\n",
    "print(f\"test_dataset_size: {len(test_dataset.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['ein', 'mann', ',', 'der', 'mit', 'einer', 'tasse', 'kaffee', 'an', 'einem', 'urinal', 'steht', '.'], 'trg': ['a', 'man', 'standing', 'at', 'a', 'urinal', 'with', 'a', 'coffee', 'cup', '.']}\n",
      "['ein', 'mann', ',', 'der', 'mit', 'einer', 'tasse', 'kaffee', 'an', 'einem', 'urinal', 'steht', '.']\n",
      "['a', 'man', 'standing', 'at', 'a', 'urinal', 'with', 'a', 'coffee', 'cup', '.']\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 중 하나를 선택해 출력\n",
    "print(vars(train_dataset.examples[30]))\n",
    "print(vars(train_dataset.examples[30])['src'])\n",
    "print(vars(train_dataset.examples[30])['trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(SRC): 7853\n",
      "len(TRG): 5893\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 만들기\n",
    "# 필드 (field) 객체 build_vocab메서드를 이용해 영어와 독어의 단어 사전을 생성\n",
    "# 최소 2번 이상 등장한 단어만을 선택\n",
    "\n",
    "SRC.build_vocab(train_dataset, min_freq=2)\n",
    "TRG.build_vocab(train_dataset, min_freq=2)\n",
    "\n",
    "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
    "print(f\"len(TRG): {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4112\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "print(TRG.vocab.stoi[\"abcabc\"]) #없는 단어 0\n",
    "print(TRG.vocab.stoi[TRG.pad_token]) #패딩 (padding): 1\n",
    "print(TRG.vocab.stoi[\"<sos>\"]) # <sos> : 2\n",
    "print(TRG.vocab.stoi[\"<eos>\"]) # <eos> : 3\n",
    "print(TRG.vocab.stoi[\"hello\"])\n",
    "print(TRG.vocab.stoi[\"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 문장에 포함된 단어가 순서대로 나열된 상태로 네트워크에 입력되어야 합니다. \n",
    "# 따라서, 하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사하도록 만들면 좋습니다. \n",
    "# 이를 위해 BucketIterator를 사용합니다. \n",
    "# 배치크기 (batch size): 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 일반적인 데이터 로더(data loader)의 iterator와 유사하게 사용 가능\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset, test_dataset), batch_size = BATCH_SIZE, device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch size: torch.Size([128, 36])\n",
      "index 0: 2\n",
      "index 1: 5\n",
      "index 2: 13\n",
      "index 3: 7\n",
      "index 4: 206\n",
      "index 5: 475\n",
      "index 6: 0\n",
      "index 7: 9\n",
      "index 8: 23\n",
      "index 9: 590\n",
      "index 10: 14\n",
      "index 11: 2511\n",
      "index 12: 7\n",
      "index 13: 33\n",
      "index 14: 3003\n",
      "index 15: 28\n",
      "index 16: 6007\n",
      "index 17: 4\n",
      "index 18: 3\n",
      "index 19: 1\n",
      "index 20: 1\n",
      "index 21: 1\n",
      "index 22: 1\n",
      "index 23: 1\n",
      "index 24: 1\n",
      "index 25: 1\n",
      "index 26: 1\n",
      "index 27: 1\n",
      "index 28: 1\n",
      "index 29: 1\n",
      "index 30: 1\n",
      "index 31: 1\n",
      "index 32: 1\n",
      "index 33: 1\n",
      "index 34: 1\n",
      "index 35: 1\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    src = batch.src\n",
    "    trg = batch.trg\n",
    "\n",
    "    print(f\"first batch size: {src.shape}\")\n",
    "\n",
    "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
    "    for i in range(src.shape[1]):\n",
    "        print(f\"index {i}: {src[0][i].item()}\")  ## 여기에서는 [Seq_num, Seq_len]\n",
    "        # .item() : tensor에 저장된 값만을 가져옴\n",
    "    # 첫번째 배치만 확인   \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi head Attention\n",
    "# attention 은 세가지 요소를 입력으로 받습니다. \n",
    "# 쿼리, 키, 값 - 현재 구현에서는 Q, K, V의 차원이 모두 같습니다. \n",
    "# 하이퍼 파라미터\n",
    "# -> hidden_dim : 하나의 단어에 대한 임베딩 차원, n_heads : 헤드의 수 = scaled dot=product attention의 개수\n",
    "# -> dropout_ratio : 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
    "        super().__init__()\n",
    "\n",
    "        assert hidden_dim % n_heads == 0\n",
    "        \n",
    "        self.hidden_dim = hidden_dim # 임베딩차원\n",
    "        self.n_heads = n_heads # 헤드의 개수 : 서로 다른 attention 컨셉의 수 \n",
    "        self.head_dim = hidden_dim//n_heads # 각 헤드에서의 임베딩의 차원\n",
    "\n",
    "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
    "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
    "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어 \n",
    "\n",
    "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio) \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('nlp_37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a94fdc193af2d2e2ae455a5778efe19a440fd0072786da8695ab4b5e5355df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
